# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/176oFWHWRUXUK-9AlXT1-T_9G4CyyjU4N
"""

import sys
!{sys.executable} -m pip install PyMuPDF
!{sys.executable} -m pip install faiss-cpu
!{sys.executable} -m pip install keybert

# ============================================
# STUDYMATE ‚Äî GRADIO VERSION (IBM GRANITE + POMODORO)
# ============================================

import fitz
import re
import time
import numpy as np
import faiss
import gradio as gr
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from keybert import KeyBERT


# ============================================
# 1. PDF TEXT EXTRACTION
# ============================================
def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    return re.sub(r"\n+", "\n", text.strip())


# ============================================
# 2. TEXT CHUNKING
# ============================================
def chunk_text(text, chunk_size=300):
    words = text.split()
    return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]


# ============================================
# 3. EMBEDDINGS + FAISS
# ============================================
encoder = SentenceTransformer("all-MiniLM-L6-v2")

def embed_chunks(chunks):
    emb = encoder.encode(chunks, show_progress_bar=True)
    return np.array(emb).astype("float32")

def build_index(emb):
    dim = emb.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(emb)
    return index


# ============================================
# 4. LLM ‚Äî IBM Granite 3.3 2B-Instruct
# ============================================
model_name = "ibm-granite/granite-3.3-2b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model_name)
llm = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto")

generator = pipeline(
    "text-generation",
    model=llm,
    tokenizer=tokenizer,
    max_new_tokens=300,
    temperature=0.2
)

def ask_llm(question, context):
    prompt = f"""
You are StudyMate, an AI study assistant.
Use ONLY the context below.

CONTEXT:
{context}

QUESTION:
{question}

ANSWER:
"""
    return generator(prompt)[0]["generated_text"]


# ============================================
# 5. VECTOR SEARCH
# ============================================
def search(query, index, chunks, top_k=5):
    q = encoder.encode([query]).astype("float32")
    scores, ids = index.search(q, top_k)
    retrieved = [chunks[i] for i in ids[0]]
    return retrieved, scores[0]


# ============================================
# 6. EXTRA FEATURES
# ============================================
kw_model = KeyBERT()

def extract_keywords(text):
    return kw_model.extract_keywords(text, top_n=15)

def auto_summary(text):
    return ask_llm("Summarize this chapter:", text)

def make_flashcards(text):
    return ask_llm("Create 10 flashcards in Q/A format:", text)


# ============================================
# 7. GLOBALS
# ============================================
GLOBAL_CHUNKS = []
GLOBAL_EMB = None
GLOBAL_INDEX = None
CHAT_HISTORY = []


# ============================================
# 8. LOAD PDFs
# ============================================
def load_pdfs(files):
    global GLOBAL_CHUNKS, GLOBAL_EMB, GLOBAL_INDEX

    full_text = ""

    for f in files:
        full_text += extract_text_from_pdf(f.name) + "\n"

    GLOBAL_CHUNKS = chunk_text(full_text)
    GLOBAL_EMB = embed_chunks(GLOBAL_CHUNKS)
    GLOBAL_INDEX = build_index(GLOBAL_EMB)

    return "PDFs processed successfully! You can now ask questions."


# ============================================
# 9. ASK QUESTION
# ============================================
def ask_question(message, history):
    global CHAT_HISTORY

    if GLOBAL_INDEX is None:
        return "‚ö†Ô∏è Please upload PDFs first.", history

    retrieved, scores = search(message, GLOBAL_INDEX, GLOBAL_CHUNKS)
    context = "\n\n".join(retrieved)
    answer = ask_llm(message, context)

    CHAT_HISTORY.append(("üßë‚Äçüéì You: " + message, "ü§ñ StudyMate: " + answer))
    return answer, CHAT_HISTORY


# ============================================
# 10. SUMMARY & FLASHCARDS
# ============================================
def get_summary():
    text = " ".join(GLOBAL_CHUNKS)
    return auto_summary(text)

def get_flashcards():
    text = " ".join(GLOBAL_CHUNKS)
    return make_flashcards(text)

def get_keywords():
    text = " ".join(GLOBAL_CHUNKS)
    return extract_keywords(text)


# ============================================
# 11. Pomodoro Timer (25-5-25 Cycle)
# ============================================
def pomodoro(mode):
    if mode == "Start Pomodoro (25 min)":
        total = 25 * 60
    elif mode == "Short Break (5 min)":
        total = 5 * 60
    elif mode == "Long Break (25 min)":
        total = 25 * 60

    return f"‚è≥ {mode} started! Timer = {total//60} minutes.\n(Use your device timer for countdown.)"


# ============================================
# 12. GRADIO UI
# ============================================
with gr.Blocks(theme="soft") as app:

    gr.Markdown("# üìò StudyMate ‚Äî AI PDF Study Assistant (Gradio + IBM Granite + Pomodoro)")

    # PDF Loader
    with gr.Row():
        pdfs = gr.File(label="Upload PDFs", file_count="multiple")
        load_btn = gr.Button("Process PDFs")

    output_status = gr.Textbox(label="Status")
    load_btn.click(load_pdfs, inputs=pdfs, outputs=output_status)

    # Chat
    chatbot = gr.Chatbot(label="Chat History")
    question = gr.Textbox(label="Ask a question")
    ask_btn = gr.Button("Ask")

    ask_btn.click(ask_question, inputs=[question, chatbot], outputs=[chatbot, chatbot])

    # Features
    with gr.Row():
        summary_btn = gr.Button("Generate Summary")
        flash_btn = gr.Button("Generate Flashcards")
        key_btn = gr.Button("Extract Keywords")

    summary_box = gr.Textbox(label="Summary")
    flash_box = gr.Textbox(label="Flashcards")
    keywords_box = gr.Textbox(label="Top Keywords")

    summary_btn.click(get_summary, outputs=summary_box)
    flash_btn.click(get_flashcards, outputs=flash_box)
    key_btn.click(get_keywords, outputs=keywords_box)

    # Pomodoro Timer
    gr.Markdown("## ‚è± Pomodoro Study Timer")
    pomo_select = gr.Radio(
        ["Start Pomodoro (25 min)", "Short Break (5 min)", "Long Break (25 min)"],
        label="Choose Timer"
    )
    pomo_out = gr.Textbox(label="Pomodoro Status")
    pomo_btn = gr.Button("Start Timer")

    pomo_btn.click(pomodoro, inputs=pomo_select, outputs=pomo_out)


app.launch()